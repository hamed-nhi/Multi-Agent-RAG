&lt;div dir=&quot;rtl&quot;&gt;
من پیش‌نویس `README.md` را بر اساس ساختار پروژه و قابلیت‌هایی که با هم پیاده‌سازی کردیم، آماده کرده‌ام. لطفاً آن را با دقت بررسی کنید و هر جا که نیاز به تغییر یا تکمیل دارد، به من اطلاع دهید.

-----

```markdown
# سیستم RAG چندعامله پیشرفته با پشتیبانی از منابع داده متنوع

**پیاده‌سازی شده توسط:** حامد نهالی (Hamed Nahali)

## مرور کلی پروژه (Overview)

این پروژه یک سیستم پیشرفته‌ی بازیابی و تولید اطلاعات مبتنی بر زبان طبیعی (RAG - Retrieval-Augmented Generation) را پیاده‌سازی می‌کند که از یک معماری چندعامله (Multi-Agent) برای تعامل با منابع داده‌ی متنوع بهره می‌برد. این سیستم با الهام از مقاله "[A Collaborative Multi-Agent Approach to Retrieval-Augmented Generation Across Diverse Data Sources]" (یک رویکرد چندعامله‌ی همکارانه برای تولید اطلاعات مبتنی بر بازیابی در منابع داده‌ی متنوع) [cite: 1] طراحی و ساخته شده است.

سیستم‌های RAG سنتی اغلب با چالش‌هایی در زمینه‌ی کارایی و دقت هنگام مواجهه با انواع مختلف پایگاه داده (مانند رابطه‌ای، اسنادی، گرافی و موتورهای جستجو) روبرو هستند[cite: 6, 18]. این پروژه با معرفی Agentهای متخصص که هر کدام برای یک نوع دیتابیس خاص بهینه شده‌اند، این محدودیت‌ها را برطرف می‌کند. این Agentها وظیفه‌ی تولید کوئری‌های دقیق و بهینه را بر عهده دارند[cite: 8, 21, 46].

علاوه بر معماری اصلی مقاله، این پیاده‌سازی شامل یک **Agent اصلاح‌کننده‌ی کوئری (Query Refiner Agent)** است که در صورت عدم موفقیت کوئری اولیه در یافتن نتایج مطلوب، به طور هوشمندانه سعی در اصلاح و بهبود آن کوئری و اجرای مجدد آن دارد. همچنین، سیستم قابلیت **پرسیدن سوالات شفاف‌سازی (Clarification Questions)** از کاربر را در صورت دریافت ورودی‌های مبهم داراست تا دقت و کارایی پاسخ‌ها را افزایش دهد.

این پروژه از LangChain و LangGraph برای ساخت و ارکستراسیون جریان کاری Agentها استفاده می‌کند و یک رابط کاربری تعاملی با Streamlit برای نمایش عملکرد سیستم و مراحل پردازش داخلی آن ارائه می‌دهد.

## ویژگی‌های کلیدی (Key Features)

* **سیستم پرسش و پاسخ با زبان طبیعی:** کاربران می‌توانند سوالات خود را به زبان ساده مطرح کنند.
* **پشتیبانی از چهار نوع دیتابیس متنوع:**
    * **SQLite:** برای داده‌های رابطه‌ای (کارمندان، دپارتمان‌ها، پروژه‌ها).
    * **MongoDB:** برای داده‌های اسنادی (مقالات پژوهشی).
    * **MeiliSearch:** برای جستجوی تمام‌متن (تیکت‌های پشتیبانی).
    * **Neo4j:** برای داده‌های گرافی (شبکه‌ی پژوهشی محققان، همکاری‌ها و پروژه‌ها).
* **معماری چندعامله:**
    * **Agent Router:** مسیریابی هوشمند سوالات به Agent متخصص مربوطه.
    * **Agentهای متخصص Query Generator:** تولید کوئری‌های بهینه و خاص هر دیتابیس (SQL, MongoDB JSON, Cypher, MeiliSearch text query).
    * **Agent Query Refiner:** اصلاح هوشمند کوئری‌های ناموفق برای افزایش شانس یافتن نتایج.
    * **Agent Response Generator:** تولید پاسخ‌های نهایی، روان و قابل فهم بر اساس داده‌های بازیابی شده.
* **قابلیت شفاف‌سازی سوال:** در صورت مبهم بودن سوال کاربر، سیستم می‌تواند سوالات بیشتری برای روشن شدن منظور کاربر بپرسد.
* **رابط کاربری تعاملی (Streamlit):**
    * نمایش تاریخچه مکالمه.
    * قابلیت مرور محتوای دیتابیس‌ها (برای کاربر عادی و حرفه‌ای).
    * نمایش مراحل پردازش داخلی و عملکرد Agentها ("Show Thinking").
    * نمایش لاگ‌های بک‌اند در UI.
* **مقاوم در برابر خطاهای رایج:** مدیریت خطاهای اتصال به API و دیتابیس‌ها.
* **مبتنی بر LangChain و LangGraph:** برای ساختاردهی و اجرای جریان‌های کاری پیچیده‌ی LLM.

## معماری سیستم (System Architecture)

معماری این سیستم از یک رویکرد چندعامله ماژولار پیروی می‌کند که در آن وظایف مختلف بین Agentهای متخصص تقسیم شده است[cite: 9, 25]. این رویکرد باعث افزایش کارایی، دقت و مقیاس‌پذیری سیستم در مقایسه با سیستم‌های RAG تک‌عامله سنتی می‌شود[cite: 26, 39].

جریان کلی به شرح زیر است:
1.  **دریافت سوال کاربر:** از طریق رابط کاربری Streamlit.
2.  **Agent Router:** سوال کاربر را تحلیل کرده و آن را به یکی از Agentهای متخصص دیتابیس (SQLite, MongoDB, MeiliSearch, Neo4j) هدایت می‌کند. اگر سوال بسیار کلی یا مبهم باشد، مسیر شفاف‌سازی یا پاسخ محاوره‌ای فعال می‌شود.
3.  **Agent متخصص Query Generator:** کوئری مناسب برای دیتابیس انتخاب شده تولید می‌کند.
4.  **Query Executor:** کوئری تولید شده را روی دیتابیس مربوطه اجرا کرده و نتایج را بازیابی می‌کند.
5.  **(در صورت نیاز) Agent Query Refiner:** اگر کوئری اولیه نتیجه‌ی مطلوبی نداشت، این Agent فعال شده و سعی در تولید یک کوئری اصلاح‌شده دارد که دوباره توسط Query Executor اجرا می‌شود.
6.  **Agent Response Generator:** داده‌های بازیابی شده (و سوال اصلی کاربر) را دریافت کرده و یک پاسخ نهایی، طبیعی و قابل فهم برای کاربر تولید می‌کند.

برای درک بهتر معماری، می‌توانید به دیاگرام ارائه‌شده در مقاله‌ی مرجع (Figure 2، صفحه ۱۱) مراجعه کنید[cite: 200]. این پروژه سعی در پیاده‌سازی و گسترش آن معماری داشته است.

## فناوری‌های استفاده شده (Tech Stack)

* **زبان برنامه‌نویسی:** Python 3.10
* **فریم‌ورک‌های اصلی LLM:** LangChain, LangGraph
* **مدل زبان بزرگ (LLM):** `meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo` (از طریق Together AI API)
* **رابط کاربری (UI):** Streamlit
* **پایگاه‌های داده:**
    * SQLite (`sqlite3`)
    * MongoDB (`pymongo`)
    * MeiliSearch (`meilisearch`)
    * Neo4j (`neo4j`)
* **سایر کتابخانه‌های مهم:** `pandas`, `python-dotenv`

## ساختار پروژه (Project Structure)


multi-agent-rag/
│
├── agents/                 # منطق Agentها (Router, Generators, Refiner, Responder)
│   ├── init.py
│   ├── router.py
│   ├── query_generator.py
│   ├── query_refiner.py
│   └── executor_and_responder.py
│
├── database/               # اسکریپت آماده‌سازی و فایل‌های دیتابیس محلی
│   ├── init.py
│   ├── populate_db.py
│   └── employees.db        # (توسط اسکریپت ایجاد می‌شود)
│
├── graph/                  # تعریف وضعیت و ساختار گراف LangGraph
│   ├── init.py
│   ├── state.py
│   └── builder.py
│
├── tools/                  # ابزارهای اتصال و اجرای کوئری روی دیتابیس‌ها
│   ├── init.py
│   └── db_tools.py
│
├── ui/                     # کدهای مربوط به رابط کاربری Streamlit
│   ├── init.py
│   └── app_ui.py
│
├── .env.example            # فایل نمونه برای متغیرهای محیطی
├── config.py               # خواندن تنظیمات و کلیدهای API
├── requirements.txt        # لیست پکیج‌های مورد نیاز
└── app.py                  #  نسخه خط فرمانی برای تست بک‌اند


## نحوه‌ی راه‌اندازی و اجرا (Setup and Running the Project)

### پیش‌نیازها

1.  **Python:** نسخه 3.9 یا بالاتر (ترجیحاً 3.10).
2.  **Pip:** برای نصب پکیج‌های پایتون.
3.  **دیتابیس‌های لوکال:**
    * **MongoDB:** باید روی سیستم شما نصب و سرویس آن در حال اجرا باشد (معمولاً روی پورت `27017`).
    * **MeiliSearch:** فایل اجرایی MeiliSearch را دانلود کرده و آن را اجرا کنید (معمولاً روی پورت `7700`).
    * **Neo4j Desktop:** آن را نصب کرده، یک پروژه جدید ایجاد کنید، و یک دیتابیس جدید با نام `mygraphdb` (یا نام دلخواه دیگر، که در این صورت باید کد را هم اصلاح کنید) با یک رمز عبور مشخص بسازید و آن را اجرا (Start) نمایید (معمولاً روی پورت `7687`).
4.  **SQLite:** نیازی به نصب جداگانه ندارد؛ در پایتون تعبیه شده است.

### مراحل نصب

1.  **کلون کردن ریپازیتوری (در صورت وجود) یا کپی کردن فایل‌ها:**
    ```bash
    # cd [PROJECT_DIRECTORY_NAME]
    # در غیر این صورت، فایل‌های پروژه را در یک پوشه قرار دهید و با cd به آن بروید.
    cd multi-agent-rag 
    ```

2.  **ایجاد و فعال‌سازی محیط مجازی:**
    ```bash
    python -m venv venv
    ```
    * برای ویندوز:
        ```bash
        venv\Scripts\activate
        ```
    * برای لینوکس/مک:
        ```bash
        source venv/bin/activate
        ```

3.  **نصب پکیج‌های مورد نیاز:**
    ```bash
    pip install -r requirements.txt
    ```

### تنظیم متغیرهای محیطی

1.  یک فایل با نام `.env` در ریشه‌ی پروژه خود (کنار `config.py`) ایجاد کنید.
2.  محتوای زیر را در آن کپی کرده و مقادیر واقعی را جایگزین کنید:
    ```env
    TOGETHER_API_KEY="YOUR_ACTUAL_TOGETHER_AI_API_KEY"
    NEO4J_PASSWORD="YOUR_ACTUAL_NEO4J_PASSWORD_FOR_MYGRAPHDB" 
    ```
    * `YOUR_ACTUAL_TOGETHER_AI_API_KEY`: کلید API معتبر خود را از وب‌سایت Together AI دریافت و اینجا قرار دهید.
    * `YOUR_ACTUAL_NEO4J_PASSWORD_FOR_MYGRAPHDB`: رمز عبوری را که هنگام ساخت دیتابیس `mygraphdb` در Neo4j Desktop تنظیم کرده‌اید، اینجا وارد کنید. (توجه: این رمز عبور در فایل `tools/db_tools.py` و `database/populate_db.py` هم باید به درستی تنظیم شده باشد یا از این متغیر محیطی خوانده شود. در پیاده‌سازی فعلی ما، مستقیماً در کد قرار داده شده و باید توسط کاربر اصلاح شود. بهتر است در آینده این بخش هم از `.env` خوانده شود).

### آماده‌سازی و اجرای دیتابیس‌ها

1.  **اطمینان از اجرای سرورهای دیتابیس:**
    * سرویس MongoDB شما باید در حال اجرا باشد.
    * سرور MeiliSearch شما باید در حال اجرا باشد.
    * دیتابیس `mygraphdb` شما در Neo4j Desktop باید در حالت "Running" باشد.

2.  **اجرای اسکریپت `populate_db.py`:**
    این اسکریپت داده‌های نمونه را در تمام چهار دیتابیس وارد می‌کند.
    ```bash
    python database/populate_db.py
    ```
    (قبل از اجرای این اسکریپت، مطمئن شوید که رمز عبور Neo4j در داخل خود اسکریپت `populate_db.py` و همچنین در `tools/db_tools.py` به درستی با رمز عبور شما جایگزین شده است. در نسخه‌ی نهایی که با هم کار کردیم، این رمز عبور در کد قرار داده شده بود.)

### اجرای برنامه

* **برای اجرای رابط کاربری Streamlit:**
    ```bash
    streamlit run ui/app_ui.py
    ```
    سپس آدرس `http://localhost:8501` را در مرورگر خود باز کنید.

* **(اختیاری) برای اجرای نسخه‌ی خط فرمان (جهت تست بک‌اند):**
    ```bash
    python app.py
    ```

## نحوه‌ی استفاده و نمونه سوالات (Usage and Example Queries)

پس از اجرای رابط کاربری، می‌توانید سوالات خود را در کادر ورودی تایپ کنید. همچنین می‌توانید از نمونه سوالات پیشنهادی که در UI نمایش داده می‌شوند، استفاده کنید.

**نمونه سوالات برای هر دیتابیس:**

* **SQLite:**
    * `Who is the lead engineer?`
    * `What is the status of the "API Integration Service" project?`
    * `Which employees work in the Data Science department?`
* **MongoDB:**
    * `Find papers on the topic of "Language Agents".`
    * `Who wrote 'Speculative RAG'?`
    * `papers about RAG from an author like "P. Lewis"` (این سوال چرخه‌ی اصلاح کوئری را فعال می‌کند)
* **MeiliSearch:**
    * `Find tickets about MySQL issues.`
    * `What support tickets were raised by Aniruddha Salve?`
* **Neo4j:**
    * `Who collaborates with Aniruddha Salve?`
    * `What is the research field of Patrick Lewis?`
    * `Find researchers working on AI in Healthcare.`

**مشاهده‌ی مراحل پردازش:**
در UI، پس از دریافت هر پاسخ، می‌توانید با باز کردن بخش "🔍 Show Processing Details & Agent Steps"، مسیر دقیق پردازش سوال خود و عملکرد هر Agent را مشاهده کنید.

## محدودیت‌ها (Limitations)

* **دقت LLM:** کیفیت پاسخ‌ها و کوئری‌های تولید شده به شدت به توانایی‌های مدل زبان استفاده شده بستگی دارد.
* **پیچیدگی سوالات:** سیستم ممکن است در درک و پردازش سوالات بسیار پیچیده یا چندوجهی که نیاز به ترکیب اطلاعات از چندین دیتابیس به صورت همزمان دارند، با چالش مواجه شود (این قابلیت هنوز پیاده‌سازی نشده است).
* **داده‌های نمونه:** داده‌های استفاده شده در دیتابیس‌ها محدود و نمونه هستند.

